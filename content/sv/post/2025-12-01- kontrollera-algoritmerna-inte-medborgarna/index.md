---
layout: post
title: Kontrollera algoritmerna, inte medborgarna
subtitle: DEBATT Åldersgränser för sociala medier är fel lösning på de problem techjättarna skapar
date: 2025-12-01 07:30:00
author: "Mattias Axell"
header-img: "featured.jpg"
image:
caption: 'Bildkälla: [**and machines**](https://unsplash.com/photos/a-group-of-colorful-objects-2yClsTFXIcE)'
draft: false
summary: DEBATT Åldersgränser för sociala medier är fel lösning på de problem techjättarna skapar, skriver fem tech-debattörer.
---

Ursprungligen publicerad 1:a december 2025 i [Tidningen Rörelsen](https://www.tidningenrorelsen.se/p/kontrollera-algoritmerna-inte-medborgarnas)

*Tänk dig situationen:* Du kommer hem från en hård arbetsdag och din tonåring sitter i soffan. Du får en hälsning innan scrollandet fortsätter på telefonen. En fråga möter dig på väg mot köket:

– Var ligger Roskilde?

– 3 mil utanför Köpenhamn i Danmark, varför undrar du?

– Mina kompisar är på festival där, lyder det sorgsna svaret. Ingen frågade om jag ville följa med.

**Snapchats kartfunktion**, som appen uppmuntrar användare att slå på, gör det nämligen möjligt att se vem som umgås med vem i realtid. För din tonåring blir känslan av utanförskap smärtsamt uppenbar.

[Danmark](https://www.svt.se/nyheter/utrikes/danmark-forbjuder-sociala-medier-for-barn) beslutade nyligen att införa en 15 års gräns på sociala medier. Vårdnadshavare kan ge tillstånd från 13 års ålder. [Australien](https://www.svt.se/nyheter/utrikes/australien-forbjuder-sociala-medier-for-barn) inför en åldersgräns på 16 år för sociala medier.

Sveriges regering [tillsatte en utredning](https://www.svt.se/nyheter/inrikes/regeringen-vill-infora-skarp-aldersgrans-for-sociala-medier) om en åldersgräns för användande av sociala medier den 10 oktober 2025, och [Socialdemokraterna](https://www.sverigesradio.se/artikel/s-vill-se-id-kontroll-for-konton-i-sociala-medier) vill se ID-kontroll på sociala medier.

**Bakgrunden är de problem som** Snapchats, Metas, Tiktoks och de andra techjättarnas affärsmodeller orsakar.

Skola, politiker och föräldrar framstår som handfallna inför de problem som lyfts fram. Därför är det lätt att förstå känslan av att vi behöver göra någonting.

Men förslagen på åldersverifiering och ID-kontroller missar målet.

**Viktigare är då att göra rätt insatser**, snarare än förhastade panikåtgärder som att påtvinga allmänheten ID-kontroller i sociala medier.

Liknande krav i exempelvis Storbritannien har lett till stora [dataläckor](https://www.404media.co/the-discord-hack-is-every-users-worst-nightmare/), där medborgares identitet exponerats på internet. Sätt alltså inte ett otympligt plåster på det öppna såret, utan motverka att det alls blir ett sår\!

**Möjligheten att kunna vara anonym på nätet är viktig.** Om det man skriver riskerar att knytas till en själv, så är man inte anonym. Risken för självcensur är stor.

Vågar du då ställa en anonym fråga i exempelvis en Facebook-grupp om hur du kommer undan en svartsjuk ex-partner? Varnar du en bekant för ett bedrägeriförsök om bedragarna kan få reda på vem du är?

Det blir omöjligt att testa teser och argument i en politisk stridsfråga, utan att behöva stå för saker du inte har tänkt igenom ordentligt i förväg.

**Men krav behöver också ställas på aktiv moderering**, och techjättarna hållas ansvariga när detta misslyckas.

Algoritmerna som styr flödena i sociala medier behöver göras transparenta. [Folkhälsomyndigheten](https://www.folkhalsomyndigheten.se/livsvillkor-levnadsvanor/digitala-medier-och-halsa/digitala-mediers-negativa-paverkan-pa-barns-och-ungas-halsa--techbolagens-ansvar/) listar ett antal exempel på algoritmer och interaktionsdesigner som de kommersiella plattformerna använder för att öka användningen och ge större annonsintäkter.

Folkhälsomyndigheten föreslår flera begränsningar man kan göra redan idag för att göra plattformarna säkrare för barn. Vi anser att ett första steg vore att ge användarna makt över algoritmerna och reglera plattformarna så att standardinställningar inte innehåller medvetet beroendeframkallande mekanismer.

**Beroendeframkallande algoritmer leder till** försämrad hälsa och sämre skolresultat. Bristande ansvar för moderering av plattformarna skapar utrymme för hatkampanjer, hot och rekrytering till kriminella gäng.

EU har redan kommit en bit på vägen att ställa krav på techjättarna genom regleringarna [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) (DSA) och [Digital Markets Act](https://en.wikipedia.org/wiki/Digital_Markets_Act) (DMA). Dessa krav behöver skärpas till ännu mer.

Det är viktigt att techjättarna tar sitt ansvar. Det är samtidigt viktigt att inte små och ideella aktörer drabbas negativt av byråkratisk börda, utan att plattformar där användarna har kontroll över algoritmerna, som Mastodon eller Pixelfed, kan fortsätta utan att tyngas av krav som inte egentligen borde beröra dem.

**Dessa förslag skulle vara en mycket bättre** användning av samhällets resurser än godtyckliga inskränkningar av medborgerliga fri- och rättigheter som riskerar att göra mer skada än nytta.

---
Mattias Axell, ordförande Open Knowledge Sweden

## Länkar:
- Ursprunglig publicering: https://www.tidningenrorelsen.se/p/kontrollera-algoritmerna-inte-medborgarnas
- Arkiverad länk: https://web.archive.org/web/20251201080639/https://www.tidningenrorelsen.se/p/kontrollera-algoritmerna-inte-medborgarnas
